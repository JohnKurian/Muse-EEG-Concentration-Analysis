{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inherited from https://www.kaggle.com/j105sahil/eeg-brainwave-dataset-mental-state\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import os\n",
    "# os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file subjectb-relaxed-2.csv\n",
      "resulting vector shape for the file (6, 989)\n",
      "Using file subjectb-concentrating-1.csv\n",
      "resulting vector shape for the file (86, 989)\n",
      "Using file subjectc-neutral-2.csv\n",
      "resulting vector shape for the file (16, 989)\n",
      "Using file subjecta-concentrating-2.csv\n",
      "resulting vector shape for the file (102, 989)\n",
      "Using file subjectc-concentrating-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectb-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectb-concentrating-2.csv\n",
      "resulting vector shape for the file (87, 989)\n",
      "Using file subjectc-neutral-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-concentrating-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectc-concentrating-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-neutral-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-concentrating-2.csv\n",
      "resulting vector shape for the file (5, 989)\n",
      "Using file subjecta-relaxed-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-concentrating-1.csv\n",
      "resulting vector shape for the file (86, 989)\n",
      "Using file subjectd-neutral-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-neutral-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-relaxed-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-neutral-2.csv\n",
      "resulting vector shape for the file (117, 989)\n",
      "Using file subjectb-neutral-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectc-relaxed-2.csv\n",
      "resulting vector shape for the file (117, 989)\n",
      "Using file subjectb-neutral-1.csv\n",
      "resulting vector shape for the file (117, 989)\n",
      "Using file subjectc-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file name-concentrating-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "FINAL_MATRIX (2479, 989)\n"
     ]
    }
   ],
   "source": [
    "#Inherited from https://github.com/jordan-bird/eeg-feature-generation\n",
    "\n",
    "from EEG_generate_training_matrix import gen_training_matrix\n",
    "\n",
    "data_directory_path = \"dataset/original_data/\"\n",
    "preprocessed_data_file_name = \"out.csv\"\n",
    "\n",
    "gen_training_matrix(data_directory_path, preprocessed_data_file_name, cols_to_ignore = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2479 rows and 989 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.374035</td>\n",
       "      <td>14.507289</td>\n",
       "      <td>17.150879</td>\n",
       "      <td>22.737512</td>\n",
       "      <td>-1.728518</td>\n",
       "      <td>4.896563</td>\n",
       "      <td>-3.355689</td>\n",
       "      <td>-5.791109</td>\n",
       "      <td>9.894234</td>\n",
       "      <td>8.559142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39.964676</td>\n",
       "      <td>23.025504</td>\n",
       "      <td>13.193117</td>\n",
       "      <td>-5.893730</td>\n",
       "      <td>3.036151</td>\n",
       "      <td>2.831246</td>\n",
       "      <td>6.528443</td>\n",
       "      <td>9.231628</td>\n",
       "      <td>41.197251</td>\n",
       "      <td>23.363905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24.023078</td>\n",
       "      <td>29.907219</td>\n",
       "      <td>27.845383</td>\n",
       "      <td>18.573773</td>\n",
       "      <td>8.949271</td>\n",
       "      <td>-0.736233</td>\n",
       "      <td>-1.146993</td>\n",
       "      <td>7.951604</td>\n",
       "      <td>19.999614</td>\n",
       "      <td>32.345596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27.458172</td>\n",
       "      <td>29.708836</td>\n",
       "      <td>36.888152</td>\n",
       "      <td>21.007500</td>\n",
       "      <td>41.389496</td>\n",
       "      <td>-13.096907</td>\n",
       "      <td>-16.285654</td>\n",
       "      <td>45.138920</td>\n",
       "      <td>25.570785</td>\n",
       "      <td>32.553577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.019732</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.711652</td>\n",
       "      <td>22.157684</td>\n",
       "      <td>31.360652</td>\n",
       "      <td>21.293648</td>\n",
       "      <td>5.794195</td>\n",
       "      <td>-6.451099</td>\n",
       "      <td>-10.117324</td>\n",
       "      <td>-9.091782</td>\n",
       "      <td>7.688381</td>\n",
       "      <td>-5.393554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2474</td>\n",
       "      <td>26.670461</td>\n",
       "      <td>22.197727</td>\n",
       "      <td>27.606980</td>\n",
       "      <td>11.749301</td>\n",
       "      <td>4.277436</td>\n",
       "      <td>1.640797</td>\n",
       "      <td>-0.139168</td>\n",
       "      <td>5.589787</td>\n",
       "      <td>24.496731</td>\n",
       "      <td>20.244755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.019489</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.019898</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>34.177766</td>\n",
       "      <td>28.848676</td>\n",
       "      <td>18.592859</td>\n",
       "      <td>-0.980387</td>\n",
       "      <td>1.378362</td>\n",
       "      <td>-0.422024</td>\n",
       "      <td>-5.625952</td>\n",
       "      <td>1.383602</td>\n",
       "      <td>34.407488</td>\n",
       "      <td>27.612628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2476</td>\n",
       "      <td>23.542398</td>\n",
       "      <td>30.860895</td>\n",
       "      <td>49.831445</td>\n",
       "      <td>18.072105</td>\n",
       "      <td>2.626985</td>\n",
       "      <td>-7.134672</td>\n",
       "      <td>14.673247</td>\n",
       "      <td>4.776835</td>\n",
       "      <td>24.062682</td>\n",
       "      <td>32.842470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2477</td>\n",
       "      <td>26.760121</td>\n",
       "      <td>24.106980</td>\n",
       "      <td>8.062375</td>\n",
       "      <td>28.150551</td>\n",
       "      <td>0.868558</td>\n",
       "      <td>-4.886292</td>\n",
       "      <td>-3.318521</td>\n",
       "      <td>2.035519</td>\n",
       "      <td>26.024857</td>\n",
       "      <td>26.027032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>0.011217</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2478</td>\n",
       "      <td>63.468953</td>\n",
       "      <td>12.248945</td>\n",
       "      <td>12.147887</td>\n",
       "      <td>51.568965</td>\n",
       "      <td>-28.347746</td>\n",
       "      <td>-5.619038</td>\n",
       "      <td>113.379181</td>\n",
       "      <td>-24.506814</td>\n",
       "      <td>63.866032</td>\n",
       "      <td>7.212688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0       17.374035    14.507289    17.150879    22.737512           -1.728518   \n",
       "1       39.964676    23.025504    13.193117    -5.893730            3.036151   \n",
       "2       24.023078    29.907219    27.845383    18.573773            8.949271   \n",
       "3       27.458172    29.708836    36.888152    21.007500           41.389496   \n",
       "4       17.711652    22.157684    31.360652    21.293648            5.794195   \n",
       "...           ...          ...          ...          ...                 ...   \n",
       "2474    26.670461    22.197727    27.606980    11.749301            4.277436   \n",
       "2475    34.177766    28.848676    18.592859    -0.980387            1.378362   \n",
       "2476    23.542398    30.860895    49.831445    18.072105            2.626985   \n",
       "2477    26.760121    24.106980     8.062375    28.150551            0.868558   \n",
       "2478    63.468953    12.248945    12.147887    51.568965          -28.347746   \n",
       "\n",
       "      lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "0               4.896563           -3.355689           -5.791109   \n",
       "1               2.831246            6.528443            9.231628   \n",
       "2              -0.736233           -1.146993            7.951604   \n",
       "3             -13.096907          -16.285654           45.138920   \n",
       "4              -6.451099          -10.117324           -9.091782   \n",
       "...                  ...                 ...                 ...   \n",
       "2474            1.640797           -0.139168            5.589787   \n",
       "2475           -0.422024           -5.625952            1.383602   \n",
       "2476           -7.134672           14.673247            4.776835   \n",
       "2477           -4.886292           -3.318521            2.035519   \n",
       "2478           -5.619038          113.379181          -24.506814   \n",
       "\n",
       "      lag1_mean_q1_0  lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  \\\n",
       "0           9.894234        8.559142  ...    0.004179    0.021494    0.004774   \n",
       "1          41.197251       23.363905  ...    0.007588    0.005935    0.005960   \n",
       "2          19.999614       32.345596  ...    0.016884    0.015968    0.006831   \n",
       "3          25.570785       32.553577  ...    0.006189    0.022736    0.001545   \n",
       "4           7.688381       -5.393554  ...    0.003812    0.004180    0.004638   \n",
       "...              ...             ...  ...         ...         ...         ...   \n",
       "2474       24.496731       20.244755  ...    0.007844    0.017493    0.019489   \n",
       "2475       34.407488       27.612628  ...    0.003372    0.004361    0.006923   \n",
       "2476       24.062682       32.842470  ...    0.008725    0.007622    0.012244   \n",
       "2477       26.024857       26.027032  ...    0.004146    0.005678    0.006463   \n",
       "2478       63.866032        7.212688  ...    0.004972    0.005026    0.002478   \n",
       "\n",
       "      freq_699_3  freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  \\\n",
       "0       0.002417    0.004154    0.024856    0.015174    0.013540    0.006765   \n",
       "1       0.010016    0.005662    0.004940    0.014456    0.004570    0.000172   \n",
       "2       0.006724    0.014860    0.019306    0.001337    0.014863    0.012660   \n",
       "3       0.018701    0.010024    0.006498    0.019732    0.006619    0.009288   \n",
       "4       0.007078    0.010407    0.000410    0.007204    0.001841    0.006530   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2474    0.015282    0.019898    0.001913    0.006720    0.010357    0.011543   \n",
       "2475    0.004548    0.007181    0.004440    0.008759    0.012330    0.011449   \n",
       "2476    0.013240    0.009559    0.012870    0.002961    0.006195    0.003554   \n",
       "2477    0.003911    0.014606    0.007157    0.006278    0.011217    0.003383   \n",
       "2478    0.002532    0.002641    0.002695    0.004708    0.004318    0.008486   \n",
       "\n",
       "      Label  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       2.0  \n",
       "...     ...  \n",
       "2474    0.0  \n",
       "2475    1.0  \n",
       "2476    1.0  \n",
       "2477    0.0  \n",
       "2478    2.0  \n",
       "\n",
       "[2479 rows x 989 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "# mental-state.csv has 2360 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df = pd.read_csv(preprocessed_data_file_name, delimiter=',', nrows = nRowsRead)\n",
    "df.dataframeName = preprocessed_data_file_name\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.374035</td>\n",
       "      <td>14.507289</td>\n",
       "      <td>17.150879</td>\n",
       "      <td>22.737512</td>\n",
       "      <td>-1.728518</td>\n",
       "      <td>4.896563</td>\n",
       "      <td>-3.355689</td>\n",
       "      <td>-5.791109</td>\n",
       "      <td>9.894234</td>\n",
       "      <td>8.559142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39.964676</td>\n",
       "      <td>23.025504</td>\n",
       "      <td>13.193117</td>\n",
       "      <td>-5.893730</td>\n",
       "      <td>3.036151</td>\n",
       "      <td>2.831246</td>\n",
       "      <td>6.528443</td>\n",
       "      <td>9.231628</td>\n",
       "      <td>41.197251</td>\n",
       "      <td>23.363905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24.023078</td>\n",
       "      <td>29.907219</td>\n",
       "      <td>27.845383</td>\n",
       "      <td>18.573773</td>\n",
       "      <td>8.949271</td>\n",
       "      <td>-0.736233</td>\n",
       "      <td>-1.146993</td>\n",
       "      <td>7.951604</td>\n",
       "      <td>19.999614</td>\n",
       "      <td>32.345596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27.458172</td>\n",
       "      <td>29.708836</td>\n",
       "      <td>36.888152</td>\n",
       "      <td>21.007500</td>\n",
       "      <td>41.389496</td>\n",
       "      <td>-13.096907</td>\n",
       "      <td>-16.285654</td>\n",
       "      <td>45.138920</td>\n",
       "      <td>25.570785</td>\n",
       "      <td>32.553577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.019732</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.711652</td>\n",
       "      <td>22.157684</td>\n",
       "      <td>31.360652</td>\n",
       "      <td>21.293648</td>\n",
       "      <td>5.794195</td>\n",
       "      <td>-6.451099</td>\n",
       "      <td>-10.117324</td>\n",
       "      <td>-9.091782</td>\n",
       "      <td>7.688381</td>\n",
       "      <td>-5.393554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    17.374035    14.507289    17.150879    22.737512           -1.728518   \n",
       "1    39.964676    23.025504    13.193117    -5.893730            3.036151   \n",
       "2    24.023078    29.907219    27.845383    18.573773            8.949271   \n",
       "3    27.458172    29.708836    36.888152    21.007500           41.389496   \n",
       "4    17.711652    22.157684    31.360652    21.293648            5.794195   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            4.896563           -3.355689           -5.791109        9.894234   \n",
       "1            2.831246            6.528443            9.231628       41.197251   \n",
       "2           -0.736233           -1.146993            7.951604       19.999614   \n",
       "3          -13.096907          -16.285654           45.138920       25.570785   \n",
       "4           -6.451099          -10.117324           -9.091782        7.688381   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0        8.559142  ...    0.004179    0.021494    0.004774    0.002417   \n",
       "1       23.363905  ...    0.007588    0.005935    0.005960    0.010016   \n",
       "2       32.345596  ...    0.016884    0.015968    0.006831    0.006724   \n",
       "3       32.553577  ...    0.006189    0.022736    0.001545    0.018701   \n",
       "4       -5.393554  ...    0.003812    0.004180    0.004638    0.007078   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0    0.004154    0.024856    0.015174    0.013540    0.006765    1.0  \n",
       "1    0.005662    0.004940    0.014456    0.004570    0.000172    1.0  \n",
       "2    0.014860    0.019306    0.001337    0.014863    0.012660    1.0  \n",
       "3    0.010024    0.006498    0.019732    0.006619    0.009288    1.0  \n",
       "4    0.010407    0.000410    0.007204    0.001841    0.006530    2.0  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=15,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=15)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(len(df)) < 0.7\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "y_train = train[\"Label\"]\n",
    "y_test = test[\"Label\"]\n",
    "\n",
    "X_train = train.drop(\"Label\", axis=1)\n",
    "X_test = test.drop(\"Label\", axis=1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 94\n",
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and statistical features\n",
    "\n",
    "### Paper: Classification of EEG Signals Based on Image Representation of Statistical Features\n",
    "#### Link: https://link.springer.com/chapter/10.1007/978-3-030-29933-0_37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = np.argsort(importances)[:729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_df = df[df.columns[:-1][ranked]] \n",
    "feature_imp_df[\"Label\"] = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=15,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=15)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_imp_df\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "y_train = train[\"Label\"]\n",
    "y_test = test[\"Label\"]\n",
    "\n",
    "X_train = train.drop(\"Label\", axis=1)\n",
    "X_test = test.drop(\"Label\", axis=1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 67\n",
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697, 729)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 0., 2.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train_np.reshape(X_train_np.shape[0], 27, 27, 1)\n",
    "X_test_np = X_test_np.reshape(X_test_np.shape[0], 27, 27, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1782, 27, 27, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(27, 27, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1782 samples, validate on 697 samples\n",
      "Epoch 1/20\n",
      "1782/1782 [==============================] - 2s 1ms/sample - loss: 23.9686 - acc: 0.6566 - val_loss: 3.4977 - val_acc: 0.6829\n",
      "Epoch 2/20\n",
      "1782/1782 [==============================] - 2s 867us/sample - loss: 5.9392 - acc: 0.7256 - val_loss: 1.1973 - val_acc: 0.8407\n",
      "Epoch 3/20\n",
      "1782/1782 [==============================] - 2s 927us/sample - loss: 3.0842 - acc: 0.8535 - val_loss: 3.9322 - val_acc: 0.8565\n",
      "Epoch 4/20\n",
      "1782/1782 [==============================] - 2s 905us/sample - loss: 5.0250 - acc: 0.8143 - val_loss: 2.5195 - val_acc: 0.8522\n",
      "Epoch 5/20\n",
      "1782/1782 [==============================] - 2s 846us/sample - loss: 2.1784 - acc: 0.8782 - val_loss: 1.0054 - val_acc: 0.8780\n",
      "Epoch 6/20\n",
      "1782/1782 [==============================] - 2s 858us/sample - loss: 0.6972 - acc: 0.9046 - val_loss: 3.8312 - val_acc: 0.8121\n",
      "Epoch 7/20\n",
      "1782/1782 [==============================] - 1s 839us/sample - loss: 1.0351 - acc: 0.9175 - val_loss: 0.7916 - val_acc: 0.9053\n",
      "Epoch 8/20\n",
      "1782/1782 [==============================] - 2s 859us/sample - loss: 0.5504 - acc: 0.9265 - val_loss: 0.3771 - val_acc: 0.9283\n",
      "Epoch 9/20\n",
      "1782/1782 [==============================] - 2s 923us/sample - loss: 0.3768 - acc: 0.9444 - val_loss: 0.4520 - val_acc: 0.8953\n",
      "Epoch 10/20\n",
      "1782/1782 [==============================] - 2s 877us/sample - loss: 0.4754 - acc: 0.9248 - val_loss: 0.3672 - val_acc: 0.9254\n",
      "Epoch 11/20\n",
      "1782/1782 [==============================] - 2s 872us/sample - loss: 0.2546 - acc: 0.9484 - val_loss: 0.5391 - val_acc: 0.9225\n",
      "Epoch 12/20\n",
      "1782/1782 [==============================] - 2s 845us/sample - loss: 0.3168 - acc: 0.9523 - val_loss: 0.3292 - val_acc: 0.9326\n",
      "Epoch 13/20\n",
      "1782/1782 [==============================] - 2s 861us/sample - loss: 0.2840 - acc: 0.9450 - val_loss: 0.4128 - val_acc: 0.9297\n",
      "Epoch 14/20\n",
      "1782/1782 [==============================] - 2s 855us/sample - loss: 0.2929 - acc: 0.9523 - val_loss: 0.2724 - val_acc: 0.9369\n",
      "Epoch 15/20\n",
      "1782/1782 [==============================] - 2s 883us/sample - loss: 0.1907 - acc: 0.9669 - val_loss: 0.2821 - val_acc: 0.9297\n",
      "Epoch 16/20\n",
      "1782/1782 [==============================] - 1s 835us/sample - loss: 0.1666 - acc: 0.9669 - val_loss: 0.2152 - val_acc: 0.9455\n",
      "Epoch 17/20\n",
      "1782/1782 [==============================] - 2s 887us/sample - loss: 0.0826 - acc: 0.9798 - val_loss: 0.2433 - val_acc: 0.9412\n",
      "Epoch 18/20\n",
      "1782/1782 [==============================] - 1s 832us/sample - loss: 0.0814 - acc: 0.9815 - val_loss: 0.3699 - val_acc: 0.9484\n",
      "Epoch 19/20\n",
      "1782/1782 [==============================] - 2s 863us/sample - loss: 0.0955 - acc: 0.9776 - val_loss: 0.5084 - val_acc: 0.9182\n",
      "Epoch 20/20\n",
      "1782/1782 [==============================] - 2s 927us/sample - loss: 0.1882 - acc: 0.9467 - val_loss: 0.2234 - val_acc: 0.9383\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_np, y_train_np, epochs=20, \n",
    "                    validation_data=(X_test_np, y_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 - 0s - loss: 0.2234 - acc: 0.9383\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_np,  y_test_np, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = np.argmax(model.predict(X_test_np), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_preds = np.sum(model_preds == y_test_np)\n",
    "correct_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
