{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inherited from https://www.kaggle.com/j105sahil/eeg-brainwave-dataset-mental-state\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import os\n",
    "# os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Script to convert from mean centered to 0 - 1600 uv\n",
    "# data = res[1:]\n",
    "# data = 0.48828125 * (np.array(data))\n",
    "# 1680 * ((data) - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dataset/transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inherited from https://github.com/jordan-bird/eeg-feature-generation\n",
    "\n",
    "# data transformation from 0 - 1600 to mean centering around 0\n",
    "# https://github.com/alexandrebarachant/muse-lsl/issues/11\n",
    "\n",
    "\n",
    "for x in os.listdir(\"dataset/original_data\"):\n",
    "\n",
    "    # Ignore non-CSV files\n",
    "    if not x.lower().endswith('.csv'):\n",
    "        continue\n",
    "    print(\"processing \", x)\n",
    "    df = pd.read_csv(\"dataset/original_data/\"+x)\n",
    "    for electrode in [\"TP9\", \"TP10\", \"AF7\", \"AF8\", \"Right AUX\"]:    \n",
    "        data = df[electrode]\n",
    "        data = 0.48828125 * (np.array(data))\n",
    "        data = 1680 * ((data) - data.min()) / (data.max() - data.min())\n",
    "        df[electrode] = data\n",
    "    df.to_csv(\"dataset/transformed_data/\"+x, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file subjectb-relaxed-2.csv\n",
      "resulting vector shape for the file (6, 989)\n",
      "Using file subjectb-concentrating-1.csv\n",
      "resulting vector shape for the file (86, 989)\n",
      "Using file subjectc-neutral-2.csv\n",
      "resulting vector shape for the file (16, 989)\n",
      "Using file subjecta-concentrating-2.csv\n",
      "resulting vector shape for the file (102, 989)\n",
      "Using file subjectc-concentrating-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectb-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectb-concentrating-2.csv\n",
      "resulting vector shape for the file (87, 989)\n",
      "Using file subjectc-neutral-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-concentrating-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectc-concentrating-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-neutral-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-concentrating-2.csv\n",
      "resulting vector shape for the file (5, 989)\n",
      "Using file subjecta-relaxed-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-concentrating-1.csv\n",
      "resulting vector shape for the file (86, 989)\n",
      "Using file subjectd-neutral-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-neutral-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectd-relaxed-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjecta-neutral-2.csv\n",
      "resulting vector shape for the file (117, 989)\n",
      "Using file subjectb-neutral-2.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file subjectc-relaxed-2.csv\n",
      "resulting vector shape for the file (117, 989)\n",
      "Using file subjectb-neutral-1.csv\n",
      "resulting vector shape for the file (117, 989)\n",
      "Using file subjectc-relaxed-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "Using file name-concentrating-1.csv\n",
      "resulting vector shape for the file (116, 989)\n",
      "FINAL_MATRIX (2479, 989)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from EEG_generate_training_matrix import gen_training_matrix\n",
    "\n",
    "data_directory_path = \"dataset/transformed_data/\"\n",
    "preprocessed_data_file_name = \"out.csv\"\n",
    "\n",
    "gen_training_matrix(data_directory_path, preprocessed_data_file_name, cols_to_ignore = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2479 rows and 989 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>921.471</td>\n",
       "      <td>789.770</td>\n",
       "      <td>975.471</td>\n",
       "      <td>897.938</td>\n",
       "      <td>26.465</td>\n",
       "      <td>80.836</td>\n",
       "      <td>34.338</td>\n",
       "      <td>-10.073</td>\n",
       "      <td>873.271</td>\n",
       "      <td>711.328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>515.449</td>\n",
       "      <td>804.758</td>\n",
       "      <td>975.718</td>\n",
       "      <td>626.218</td>\n",
       "      <td>-51.633</td>\n",
       "      <td>-126.589</td>\n",
       "      <td>162.958</td>\n",
       "      <td>0.115</td>\n",
       "      <td>540.817</td>\n",
       "      <td>920.374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>420.767</td>\n",
       "      <td>753.867</td>\n",
       "      <td>906.633</td>\n",
       "      <td>499.492</td>\n",
       "      <td>82.219</td>\n",
       "      <td>76.523</td>\n",
       "      <td>47.940</td>\n",
       "      <td>67.416</td>\n",
       "      <td>371.036</td>\n",
       "      <td>719.579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>657.403</td>\n",
       "      <td>1473.209</td>\n",
       "      <td>674.606</td>\n",
       "      <td>723.010</td>\n",
       "      <td>-52.555</td>\n",
       "      <td>16.960</td>\n",
       "      <td>223.668</td>\n",
       "      <td>-116.777</td>\n",
       "      <td>666.154</td>\n",
       "      <td>1451.359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1015.545</td>\n",
       "      <td>706.362</td>\n",
       "      <td>507.026</td>\n",
       "      <td>1027.509</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-11.982</td>\n",
       "      <td>-97.209</td>\n",
       "      <td>-23.571</td>\n",
       "      <td>1039.092</td>\n",
       "      <td>709.531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2474</td>\n",
       "      <td>965.036</td>\n",
       "      <td>826.032</td>\n",
       "      <td>940.396</td>\n",
       "      <td>937.369</td>\n",
       "      <td>-41.855</td>\n",
       "      <td>-33.397</td>\n",
       "      <td>-133.594</td>\n",
       "      <td>-51.514</td>\n",
       "      <td>1016.081</td>\n",
       "      <td>833.538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>1148.750</td>\n",
       "      <td>857.038</td>\n",
       "      <td>846.509</td>\n",
       "      <td>1063.284</td>\n",
       "      <td>17.402</td>\n",
       "      <td>13.010</td>\n",
       "      <td>2.028</td>\n",
       "      <td>-34.279</td>\n",
       "      <td>1149.221</td>\n",
       "      <td>848.629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2476</td>\n",
       "      <td>1030.443</td>\n",
       "      <td>862.922</td>\n",
       "      <td>783.806</td>\n",
       "      <td>1130.396</td>\n",
       "      <td>-12.548</td>\n",
       "      <td>-36.101</td>\n",
       "      <td>-127.865</td>\n",
       "      <td>-31.576</td>\n",
       "      <td>1039.389</td>\n",
       "      <td>892.795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2477</td>\n",
       "      <td>1115.711</td>\n",
       "      <td>704.877</td>\n",
       "      <td>641.492</td>\n",
       "      <td>1117.700</td>\n",
       "      <td>-3.971</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-19.994</td>\n",
       "      <td>-34.478</td>\n",
       "      <td>1135.100</td>\n",
       "      <td>684.976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2478</td>\n",
       "      <td>1288.862</td>\n",
       "      <td>1408.336</td>\n",
       "      <td>970.906</td>\n",
       "      <td>1329.102</td>\n",
       "      <td>-7.136</td>\n",
       "      <td>1.515</td>\n",
       "      <td>-7.833</td>\n",
       "      <td>-20.244</td>\n",
       "      <td>1295.497</td>\n",
       "      <td>1406.916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0         921.471      789.770      975.471      897.938              26.465   \n",
       "1         515.449      804.758      975.718      626.218             -51.633   \n",
       "2         420.767      753.867      906.633      499.492              82.219   \n",
       "3         657.403     1473.209      674.606      723.010             -52.555   \n",
       "4        1015.545      706.362      507.026     1027.509               0.858   \n",
       "...           ...          ...          ...          ...                 ...   \n",
       "2474      965.036      826.032      940.396      937.369             -41.855   \n",
       "2475     1148.750      857.038      846.509     1063.284              17.402   \n",
       "2476     1030.443      862.922      783.806     1130.396             -12.548   \n",
       "2477     1115.711      704.877      641.492     1117.700              -3.971   \n",
       "2478     1288.862     1408.336      970.906     1329.102              -7.136   \n",
       "\n",
       "      lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "0                 80.836              34.338             -10.073   \n",
       "1               -126.589             162.958               0.115   \n",
       "2                 76.523              47.940              67.416   \n",
       "3                 16.960             223.668            -116.777   \n",
       "4                -11.982             -97.209             -23.571   \n",
       "...                  ...                 ...                 ...   \n",
       "2474             -33.397            -133.594             -51.514   \n",
       "2475              13.010               2.028             -34.279   \n",
       "2476             -36.101            -127.865             -31.576   \n",
       "2477               0.391             -19.994             -34.478   \n",
       "2478               1.515              -7.833             -20.244   \n",
       "\n",
       "      lag1_mean_q1_0  lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  \\\n",
       "0            873.271         711.328  ...       0.005       0.009       0.017   \n",
       "1            540.817         920.374  ...       0.003       0.006       0.012   \n",
       "2            371.036         719.579  ...       0.012       0.006       0.007   \n",
       "3            666.154        1451.359  ...       0.008       0.004       0.008   \n",
       "4           1039.092         709.531  ...       0.006       0.006       0.008   \n",
       "...              ...             ...  ...         ...         ...         ...   \n",
       "2474        1016.081         833.538  ...       0.001       0.007       0.004   \n",
       "2475        1149.221         848.629  ...       0.003       0.027       0.010   \n",
       "2476        1039.389         892.795  ...       0.005       0.001       0.002   \n",
       "2477        1135.100         684.976  ...       0.005       0.001       0.002   \n",
       "2478        1295.497        1406.916  ...       0.003       0.002       0.001   \n",
       "\n",
       "      freq_699_3  freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  \\\n",
       "0          0.006       0.003       0.010       0.008       0.008       0.015   \n",
       "1          0.003       0.010       0.013       0.006       0.005       0.005   \n",
       "2          0.005       0.003       0.009       0.007       0.012       0.003   \n",
       "3          0.001       0.002       0.009       0.007       0.008       0.008   \n",
       "4          0.018       0.003       0.004       0.003       0.002       0.010   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2474       0.005       0.009       0.007       0.007       0.005       0.004   \n",
       "2475       0.020       0.006       0.023       0.019       0.006       0.017   \n",
       "2476       0.001       0.003       0.001       0.002       0.006       0.003   \n",
       "2477       0.007       0.005       0.002       0.006       0.003       0.004   \n",
       "2478       0.001       0.003       0.004       0.007       0.004       0.005   \n",
       "\n",
       "      Label  \n",
       "0     2.000  \n",
       "1     0.000  \n",
       "2     0.000  \n",
       "3     0.000  \n",
       "4     1.000  \n",
       "...     ...  \n",
       "2474  2.000  \n",
       "2475  2.000  \n",
       "2476  2.000  \n",
       "2477  2.000  \n",
       "2478  0.000  \n",
       "\n",
       "[2479 rows x 989 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "# mental-state.csv has 2360 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df = pd.read_csv(preprocessed_data_file_name, delimiter=',', nrows = nRowsRead)\n",
    "df.dataframeName = preprocessed_data_file_name\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>921.471</td>\n",
       "      <td>789.770</td>\n",
       "      <td>975.471</td>\n",
       "      <td>897.938</td>\n",
       "      <td>26.465</td>\n",
       "      <td>80.836</td>\n",
       "      <td>34.338</td>\n",
       "      <td>-10.073</td>\n",
       "      <td>873.271</td>\n",
       "      <td>711.328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>515.449</td>\n",
       "      <td>804.758</td>\n",
       "      <td>975.718</td>\n",
       "      <td>626.218</td>\n",
       "      <td>-51.633</td>\n",
       "      <td>-126.589</td>\n",
       "      <td>162.958</td>\n",
       "      <td>0.115</td>\n",
       "      <td>540.817</td>\n",
       "      <td>920.374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>420.767</td>\n",
       "      <td>753.867</td>\n",
       "      <td>906.633</td>\n",
       "      <td>499.492</td>\n",
       "      <td>82.219</td>\n",
       "      <td>76.523</td>\n",
       "      <td>47.940</td>\n",
       "      <td>67.416</td>\n",
       "      <td>371.036</td>\n",
       "      <td>719.579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>657.403</td>\n",
       "      <td>1473.209</td>\n",
       "      <td>674.606</td>\n",
       "      <td>723.010</td>\n",
       "      <td>-52.555</td>\n",
       "      <td>16.960</td>\n",
       "      <td>223.668</td>\n",
       "      <td>-116.777</td>\n",
       "      <td>666.154</td>\n",
       "      <td>1451.359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1015.545</td>\n",
       "      <td>706.362</td>\n",
       "      <td>507.026</td>\n",
       "      <td>1027.509</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-11.982</td>\n",
       "      <td>-97.209</td>\n",
       "      <td>-23.571</td>\n",
       "      <td>1039.092</td>\n",
       "      <td>709.531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0      921.471      789.770      975.471      897.938              26.465   \n",
       "1      515.449      804.758      975.718      626.218             -51.633   \n",
       "2      420.767      753.867      906.633      499.492              82.219   \n",
       "3      657.403     1473.209      674.606      723.010             -52.555   \n",
       "4     1015.545      706.362      507.026     1027.509               0.858   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0              80.836              34.338             -10.073         873.271   \n",
       "1            -126.589             162.958               0.115         540.817   \n",
       "2              76.523              47.940              67.416         371.036   \n",
       "3              16.960             223.668            -116.777         666.154   \n",
       "4             -11.982             -97.209             -23.571        1039.092   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0         711.328  ...       0.005       0.009       0.017       0.006   \n",
       "1         920.374  ...       0.003       0.006       0.012       0.003   \n",
       "2         719.579  ...       0.012       0.006       0.007       0.005   \n",
       "3        1451.359  ...       0.008       0.004       0.008       0.001   \n",
       "4         709.531  ...       0.006       0.006       0.008       0.018   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0       0.003       0.010       0.008       0.008       0.015  2.000  \n",
       "1       0.010       0.013       0.006       0.005       0.005  0.000  \n",
       "2       0.003       0.009       0.007       0.012       0.003  0.000  \n",
       "3       0.002       0.009       0.007       0.008       0.008  0.000  \n",
       "4       0.003       0.004       0.003       0.002       0.010  1.000  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=15,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=15)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(len(df)) < 0.7\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "y_train = train[\"Label\"]\n",
    "y_test = test[\"Label\"]\n",
    "\n",
    "X_train = train.drop(\"Label\", axis=1)\n",
    "X_test = test.drop(\"Label\", axis=1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 108\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 2., 0., 2., 2., 2., 0., 2., 2., 1., 1., 1., 1., 2., 2.,\n",
       "       1., 0., 1., 0., 1., 2., 1., 2., 0., 1., 0., 2., 1., 2., 2., 1., 1.,\n",
       "       1., 1., 2., 0., 2., 1., 0., 2., 2., 0., 0., 1., 2., 0., 2., 1., 1.,\n",
       "       2., 0., 1., 2., 0., 2., 1., 1., 1., 0., 2., 1., 2., 1., 1., 1., 0.,\n",
       "       2., 0., 2., 1., 2., 2., 1., 0., 2., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 2., 2., 0., 0., 1., 1., 1., 2., 1., 1., 1., 2., 0., 2., 1.,\n",
       "       0., 2., 1., 2., 1., 0., 1., 0., 1., 1., 2., 1., 1., 0., 1., 2., 2.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 2., 1., 1., 0., 0., 0., 2., 1., 1.,\n",
       "       0., 2., 1., 1., 1., 2., 0., 2., 2., 0., 0., 1., 1., 1., 2., 1., 1.,\n",
       "       2., 2., 2., 2., 0., 0., 2., 2., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 2., 1., 0., 2., 2., 2., 1., 1., 1., 0.,\n",
       "       2., 1., 1., 1., 1., 2., 1., 0., 1., 1., 2., 1., 0., 0., 0., 2., 2.,\n",
       "       0., 2., 2., 2., 1., 2., 2., 1., 1., 1., 2., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 2., 2., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 2., 1., 1., 2.,\n",
       "       2., 0., 0., 1., 2., 2., 1., 0., 1., 2., 2., 1., 1., 0., 1., 1., 2.,\n",
       "       0., 2., 2., 1., 1., 2., 1., 1., 2., 0., 1., 0., 2., 2., 2., 0., 1.,\n",
       "       0., 2., 0., 0., 1., 2., 1., 2., 2., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 2., 2., 1., 1., 0., 1., 1., 2., 2., 0., 1., 0., 0., 1.,\n",
       "       2., 0., 1., 0., 1., 1., 2., 1., 1., 1., 2., 2., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 2., 2., 2., 0., 2., 1., 0., 1., 0., 2., 1.,\n",
       "       0., 2., 1., 0., 1., 1., 0., 2., 1., 1., 1., 2., 1., 1., 1., 1., 0.,\n",
       "       2., 0., 1., 2., 1., 1., 0., 1., 2., 0., 2., 1., 0., 0., 1., 1., 1.,\n",
       "       2., 2., 0., 2., 0., 0., 2., 0., 1., 0., 2., 0., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 2., 1., 0., 2., 1., 1., 2., 2., 2., 0., 1., 1., 1., 2.,\n",
       "       2., 2., 1., 1., 0., 2., 1., 0., 0., 2., 1., 1., 1., 0., 1., 0., 2.,\n",
       "       1., 2., 1., 1., 1., 2., 0., 1., 1., 1., 2., 0., 1., 1., 2., 1., 2.,\n",
       "       2., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 2.,\n",
       "       1., 2., 0., 2., 0., 1., 2., 2., 2., 2., 2., 0., 2., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 2., 2., 2., 0., 1., 0., 2., 0., 1., 1.,\n",
       "       0., 2., 1., 0., 1., 0., 1., 2., 2., 1., 2., 2., 2., 2., 2., 1., 1.,\n",
       "       0., 1., 1., 1., 2., 0., 2., 2., 0., 1., 1., 2., 2., 2., 0., 1., 0.,\n",
       "       2., 2., 0., 1., 1., 0., 1., 2., 1., 2., 1., 1., 0., 1., 0., 0., 2.,\n",
       "       1., 2., 1., 1., 0., 0., 1., 0., 2., 2., 1., 1., 2., 2., 2., 2., 2.,\n",
       "       0., 0., 1., 1., 0., 2., 0., 1., 1., 1., 1., 2., 2., 1., 1., 0., 2.,\n",
       "       2., 0., 0., 1., 2., 1., 1., 1., 1., 2., 1., 2., 2., 2., 1., 1., 2.,\n",
       "       0., 1., 1., 1., 1., 2., 0., 2., 1., 0., 0., 2., 2., 2., 1., 2., 0.,\n",
       "       2., 0., 0., 2., 1., 0., 2., 1., 2., 0., 0., 0., 2., 2., 1., 1., 1.,\n",
       "       2., 1., 1., 0., 2., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 2., 1.,\n",
       "       1., 2., 2., 1., 1., 1., 1., 1., 0., 1., 2., 1., 2., 2., 2., 0., 2.,\n",
       "       2., 2., 1., 1., 0., 1., 1., 2., 2., 2., 2., 2., 2., 0., 2., 1., 2.,\n",
       "       0., 1., 1., 2., 1., 0., 0., 2., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 2., 2., 1., 1., 2., 1., 1.])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on muse monitor converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1072 rows and 989 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>803.329</td>\n",
       "      <td>804.456</td>\n",
       "      <td>805.762</td>\n",
       "      <td>804.614</td>\n",
       "      <td>-13.661</td>\n",
       "      <td>-5.072</td>\n",
       "      <td>2.149</td>\n",
       "      <td>-14.104</td>\n",
       "      <td>799.988</td>\n",
       "      <td>805.709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>803.563</td>\n",
       "      <td>805.615</td>\n",
       "      <td>805.260</td>\n",
       "      <td>806.155</td>\n",
       "      <td>-6.685</td>\n",
       "      <td>4.992</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-8.089</td>\n",
       "      <td>799.074</td>\n",
       "      <td>804.240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.027</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>803.628</td>\n",
       "      <td>806.789</td>\n",
       "      <td>796.698</td>\n",
       "      <td>806.028</td>\n",
       "      <td>2.729</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-3.360</td>\n",
       "      <td>2.558</td>\n",
       "      <td>803.496</td>\n",
       "      <td>808.147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.022</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>799.252</td>\n",
       "      <td>799.028</td>\n",
       "      <td>806.605</td>\n",
       "      <td>801.388</td>\n",
       "      <td>-11.970</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>-6.542</td>\n",
       "      <td>-15.084</td>\n",
       "      <td>819.014</td>\n",
       "      <td>801.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>866.258</td>\n",
       "      <td>863.628</td>\n",
       "      <td>868.202</td>\n",
       "      <td>866.309</td>\n",
       "      <td>-78.630</td>\n",
       "      <td>-65.371</td>\n",
       "      <td>-53.748</td>\n",
       "      <td>-53.097</td>\n",
       "      <td>975.256</td>\n",
       "      <td>958.946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1067</td>\n",
       "      <td>800.177</td>\n",
       "      <td>804.359</td>\n",
       "      <td>802.449</td>\n",
       "      <td>805.067</td>\n",
       "      <td>-11.726</td>\n",
       "      <td>5.269</td>\n",
       "      <td>-1.249</td>\n",
       "      <td>-25.614</td>\n",
       "      <td>805.061</td>\n",
       "      <td>803.167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.021</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1068</td>\n",
       "      <td>804.134</td>\n",
       "      <td>806.737</td>\n",
       "      <td>804.261</td>\n",
       "      <td>806.458</td>\n",
       "      <td>8.902</td>\n",
       "      <td>2.076</td>\n",
       "      <td>3.673</td>\n",
       "      <td>8.926</td>\n",
       "      <td>799.646</td>\n",
       "      <td>804.508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1069</td>\n",
       "      <td>797.217</td>\n",
       "      <td>802.635</td>\n",
       "      <td>803.620</td>\n",
       "      <td>800.074</td>\n",
       "      <td>-2.330</td>\n",
       "      <td>-6.274</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-2.135</td>\n",
       "      <td>800.297</td>\n",
       "      <td>808.660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>804.163</td>\n",
       "      <td>812.713</td>\n",
       "      <td>805.394</td>\n",
       "      <td>805.061</td>\n",
       "      <td>22.620</td>\n",
       "      <td>34.080</td>\n",
       "      <td>-14.478</td>\n",
       "      <td>0.186</td>\n",
       "      <td>791.093</td>\n",
       "      <td>778.553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1071</td>\n",
       "      <td>799.585</td>\n",
       "      <td>800.635</td>\n",
       "      <td>811.432</td>\n",
       "      <td>800.428</td>\n",
       "      <td>-8.318</td>\n",
       "      <td>-14.416</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-20.230</td>\n",
       "      <td>799.726</td>\n",
       "      <td>810.767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.021</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0         803.329      804.456      805.762      804.614             -13.661   \n",
       "1         803.563      805.615      805.260      806.155              -6.685   \n",
       "2         803.628      806.789      796.698      806.028               2.729   \n",
       "3         799.252      799.028      806.605      801.388             -11.970   \n",
       "4         866.258      863.628      868.202      866.309             -78.630   \n",
       "...           ...          ...          ...          ...                 ...   \n",
       "1067      800.177      804.359      802.449      805.067             -11.726   \n",
       "1068      804.134      806.737      804.261      806.458               8.902   \n",
       "1069      797.217      802.635      803.620      800.074              -2.330   \n",
       "1070      804.163      812.713      805.394      805.061              22.620   \n",
       "1071      799.585      800.635      811.432      800.428              -8.318   \n",
       "\n",
       "      lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "0                 -5.072               2.149             -14.104   \n",
       "1                  4.992              -0.706              -8.089   \n",
       "2                 -0.436              -3.360               2.558   \n",
       "3                 -1.358              -6.542             -15.084   \n",
       "4                -65.371             -53.748             -53.097   \n",
       "...                  ...                 ...                 ...   \n",
       "1067               5.269              -1.249             -25.614   \n",
       "1068               2.076               3.673               8.926   \n",
       "1069              -6.274              -0.525              -2.135   \n",
       "1070              34.080             -14.478               0.186   \n",
       "1071             -14.416              -1.855             -20.230   \n",
       "\n",
       "      lag1_mean_q1_0  lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  \\\n",
       "0            799.988         805.709  ...       0.020       0.016       0.011   \n",
       "1            799.074         804.240  ...       0.019       0.025       0.013   \n",
       "2            803.496         808.147  ...       0.016       0.022       0.023   \n",
       "3            819.014         801.020  ...       0.018       0.023       0.007   \n",
       "4            975.256         958.946  ...       0.014       0.014       0.010   \n",
       "...              ...             ...  ...         ...         ...         ...   \n",
       "1067         805.061         803.167  ...       0.031       0.022       0.020   \n",
       "1068         799.646         804.508  ...       0.015       0.008       0.009   \n",
       "1069         800.297         808.660  ...       0.029       0.019       0.020   \n",
       "1070         791.093         778.553  ...       0.001       0.007       0.001   \n",
       "1071         799.726         810.767  ...       0.037       0.036       0.002   \n",
       "\n",
       "      freq_699_3  freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  \\\n",
       "0          0.012       0.015       0.009       0.011       0.017       0.004   \n",
       "1          0.006       0.008       0.011       0.010       0.004       0.027   \n",
       "2          0.012       0.020       0.016       0.015       0.007       0.022   \n",
       "3          0.011       0.010       0.011       0.014       0.014       0.011   \n",
       "4          0.003       0.009       0.008       0.002       0.015       0.008   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1067       0.009       0.006       0.015       0.006       0.033       0.021   \n",
       "1068       0.005       0.008       0.001       0.005       0.006       0.006   \n",
       "1069       0.033       0.025       0.014       0.009       0.002       0.007   \n",
       "1070       0.006       0.003       0.005       0.003       0.003       0.002   \n",
       "1071       0.023       0.009       0.013       0.003       0.020       0.021   \n",
       "\n",
       "      Label  \n",
       "0     2.000  \n",
       "1     2.000  \n",
       "2     2.000  \n",
       "3     2.000  \n",
       "4     2.000  \n",
       "...     ...  \n",
       "1067  2.000  \n",
       "1068  2.000  \n",
       "1069  2.000  \n",
       "1070  2.000  \n",
       "1071  2.000  \n",
       "\n",
       "[1072 rows x 989 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "# mental-state.csv has 2360 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "preprocessed_data_file_name = \"out_testing.csv\"\n",
    "df = pd.read_csv(preprocessed_data_file_name, delimiter=',', nrows = nRowsRead)\n",
    "df.dataframeName = preprocessed_data_file_name\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_muse_test = df.drop(\"Label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_muse_pred = model.predict_proba(X_muse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([341.0599802, 408.5203079, 322.4197119])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debbie league part 1\n",
    "np.sum(y_muse_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.85876267, 44.79209561, 30.34914172])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eyes closed\n",
    "np.sum(y_muse_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.31997684, 8.35767198, 5.32235118])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eyes open 250hz\n",
    "np.sum(y_muse_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.18621703, 62.64924141, 50.16454156])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eyes open relaxed\n",
    "np.sum(y_muse_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([135.15533979, 147.3246686 , 129.51999161])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#league part 2\n",
    "np.sum(y_muse_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(y_muse_pred, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 10.],\n",
       "       [ 1., 89.],\n",
       "       [ 2., 11.]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eyes closed \n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 37.],\n",
       "       [ 1., 89.],\n",
       "       [ 2., 29.]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eyes open relaxed\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 311.],\n",
       "       [  1., 641.],\n",
       "       [  2., 120.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#league part 1\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 158.],\n",
       "       [  1., 181.],\n",
       "       [  2.,  73.]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#league part 2\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and statistical features\n",
    "\n",
    "### Paper: Classification of EEG Signals Based on Image Representation of Statistical Features\n",
    "#### Link: https://link.springer.com/chapter/10.1007/978-3-030-29933-0_37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = np.argsort(importances)[:729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_df = df[df.columns[:-1][ranked]] \n",
    "feature_imp_df[\"Label\"] = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=15,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=15)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_imp_df\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "y_train = train[\"Label\"]\n",
    "y_test = test[\"Label\"]\n",
    "\n",
    "X_train = train.drop(\"Label\", axis=1)\n",
    "X_test = test.drop(\"Label\", axis=1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 0\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 729)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train_np.reshape(X_train_np.shape[0], 27, 27, 1)\n",
    "X_test_np = X_test_np.reshape(X_test_np.shape[0], 27, 27, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 27, 27, 1)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(27, 27, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 746 samples, validate on 326 samples\n",
      "Epoch 1/20\n",
      "746/746 [==============================] - 1s 2ms/sample - loss: 2.3129 - acc: 0.9571 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "746/746 [==============================] - 1s 895us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "746/746 [==============================] - 1s 831us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "746/746 [==============================] - 1s 837us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "746/746 [==============================] - 1s 824us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "746/746 [==============================] - 1s 835us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "746/746 [==============================] - 1s 962us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "746/746 [==============================] - 1s 984us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "746/746 [==============================] - 1s 956us/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "746/746 [==============================] - 1s 1ms/sample - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      " 64/746 [=>............................] - ETA: 1s - loss: 0.0000e+00 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-e62b04ad4817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(X_train_np, y_train_np, epochs=20, \n\u001b[0;32m----> 6\u001b[0;31m                     validation_data=(X_test_np, y_test_np))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_np, y_train_np, epochs=20, \n",
    "                    validation_data=(X_test_np, y_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 - 0s - loss: 0.2234 - acc: 0.9383\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_np,  y_test_np, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = np.argmax(model.predict(X_test_np), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_preds = np.sum(model_preds == y_test_np)\n",
    "correct_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
